{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.image as mpimg\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "from keras.layers import Lambda, Input, GlobalAveragePooling2D,BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.applications.nasnet import NASNetLarge, preprocess_input\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "import time \n",
    "print('yee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('Database1/labels.csv')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(list(set(labels['breed'])))\n",
    "n_classes = len(classes)\n",
    "print('Total unique breed {}'.format(n_classes))\n",
    "class_to_num = dict(zip(classes, range(n_classes)))\n",
    "class_to_num\n",
    "input_shape = (331,331,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagesarray(directory, label_dataframe, target_size = input_shape):\n",
    "    image_labels = label_dataframe['breed']\n",
    "    images = np.zeros([len(label_dataframe), target_size[0], target_size[1], target_size[2]],dtype=np.uint8)\n",
    "    y = np.zeros([len(label_dataframe),1],dtype = np.uint8)\n",
    "    for ix, image_name in enumerate(tqdm(label_dataframe['id'].values)):\n",
    "        img_dir = os.path.join(directory, image_name + '.jpg')\n",
    "        img = load_img(img_dir, target_size = target_size)\n",
    "        images[ix]=img\n",
    "        del img  \n",
    "        dog_breed = image_labels[ix]\n",
    "        y[ix] = class_to_num[dog_breed]\n",
    "    y = to_categorical(y)\n",
    "    return images,y\n",
    "t = time.time()\n",
    "X,y = imagesarray('Database1/train', labels[:])\n",
    "print('runtime in seconds: {}'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,40))\n",
    "n=1\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(5, 5, i+1)\n",
    "    plt.title(classes[np.where(y[i] ==1)[0][0]])\n",
    "    plt.imshow(X[i].astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(list(set(labels['breed'])))\n",
    "n_classes = len(classes)\n",
    "print('Total unique breed {}'.format(n_classes))\n",
    "class_to_num = dict(zip(classes, range(n_classes)))\n",
    "class_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5,verbose = 1)\n",
    "EarlyStop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "batch_size= 128\n",
    "epochs=50\n",
    "learn_rate=.001\n",
    "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
    "adam=Adam(learning_rate=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None,  amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (331,331,3)\n",
    "def getfeatures(model_name, model_preprocessor, input_size, data):\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = Lambda(model_preprocessor)(input_layer)\n",
    "    base_model = model_name(weights='imagenet', include_top=False,input_shape=input_size)(preprocessor)\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs = input_layer, outputs = avg)\n",
    "    feature_maps = feature_extractor.predict(data, verbose=1)\n",
    "    print('Feature maps shape: ', feature_maps.shape)\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Extract features\n",
    "inception_preprocessor = preprocess_input\n",
    "inception_features = getfeatures(InceptionV3,inception_preprocessor,img_size, X)\n",
    "xception_preprocessor = preprocess_input\n",
    "xception_features = getfeatures(Xception,xception_preprocessor,img_size, X)\n",
    "nasnet_preprocessor = preprocess_input\n",
    "nasnet_features = getfeatures(NASNetLarge,nasnet_preprocessor,img_size, X)\n",
    "inc_resnet_preprocessor = preprocess_input\n",
    "inc_resnet_features = getfeatures(InceptionResNetV2,inc_resnet_preprocessor,img_size, X)\n",
    "final_features = np.concatenate([inception_features,xception_features,nasnet_features,inc_resnet_features,], axis=-1) \n",
    "print('Final feature maps shape', final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.7,input_shape=(final_features.shape[1],)))\n",
    "model.add(Dense(n_classes,activation= 'softmax'))\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#Training the model. \n",
    "history = model.fit(final_features, y,batch_size=batch_size,epochs=epochs,validation_split=0.2,callbacks=[lrr,EarlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_array_test(test_path, img_size = (331,331,3)):\n",
    "    test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n",
    "    data_size = len(test_filenames)\n",
    "    images = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)  \n",
    "    for ix,img_dir in enumerate(tqdm(test_filenames)):\n",
    "        img = load_img(img_dir, target_size = img_size)\n",
    "        images[ix]=img\n",
    "        del img\n",
    "    print('Ouptut Data Size: ', images.shape)\n",
    "    return images\n",
    "test_data = images_to_array_test('Database1/test/', img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extact_features(data):\n",
    "    inception_features = getfeatures(InceptionV3, inception_preprocessor, img_size, data)\n",
    "    xception_features = getfeatures(Xception, xception_preprocessor, img_size, data)\n",
    "    nasnet_features = getfeatures(NASNetLarge, nasnet_preprocessor, img_size, data)\n",
    "    inc_resnet_features = getfeatures(InceptionResNetV2, inc_resnet_preprocessor, img_size, data)\n",
    "    final_features = np.concatenate([inception_features,xception_features,nasnet_features,inc_resnet_features],axis=-1)\n",
    "    print('Final feature maps shape', final_features.shape)\n",
    "    gc.collect()\n",
    "    return final_features\n",
    "test_features = extact_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mpimg.imread('251106815_909084029712681_5221780040308292698_n.jpg'))\n",
    "img_g = load_img('251106815_909084029712681_5221780040308292698_n.jpg',target_size = img_size)\n",
    "img_g = np.expand_dims(img_g, axis=0)\n",
    "img_g\n",
    "test_features = extact_features(img_g)\n",
    "predg = model.predict(test_features)\n",
    "print(f\"Predicted label: {classes[np.argmax(predg[0])]}\")\n",
    "print(f\"Probability of prediction): {round(np.max(predg[0])) * 100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
